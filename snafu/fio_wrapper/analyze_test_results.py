# uncomment the next line to enable directly running script from the shell
##!/usr/bin/python3
#
# script to calculate statistics from raw elasticsearch results
# generated by benchmark-wrapper/snafu/fio_wrapper
# NOTE: to avoid an error importing snafu.utils.fetch_es_test_results:
#   export PYTHONPATH=your-benchmark-wrapper-clone-directory
#
# for example, to find test uuids for fio results, do (after adjusting date)
#   python3 snafu/utils/query_result_uuids.py ripsaw-fio-results timestamp_end 2021-09-01T00:00:00Z

# import json
import sys

import numpy

from snafu.utils.fetch_es_test_results import connect_es, result_generator_for_uuid

NOTOK = 1
KiB_per_MiB = 1 << 10
MSEC_PER_SEC = 1000.0


class FioStatException(Exception):
    pass


index_name = "ripsaw-fio-results"
# used by strptime()
datetime_format = "%Y-%m-%dT%H:%M:%S.%f%z"

if len(sys.argv) < 2:
    print("ERROR: must supply uuid of test")
    sys.exit(NOTOK)

uuid = sys.argv[1]

uuid_query = {
    "query": {"simple_query_string": {"query": uuid, "fields": ["uuid"], "default_operator": "and"}}
}

es = connect_es()

optype_dict = {}
max_sample = 0
threads_per_pod = None
pods_per_run = 0
prev_job_options = None

hit_generator = result_generator_for_uuid(es, index_name, uuid)
for hit in hit_generator:
    src = hit["_source"]
    # print(json.dumps(src, indent=2))

    try:
        jobname_all_clients = src["fio"]["jobname"]
        if jobname_all_clients == "All clients":
            # don't count these, these are fio aggregations
            continue
    except KeyError:
        pass

    sample = int(src["sample"])
    try:
        prev_job_options = src["fio"]["job options"]
        rw = prev_job_options["rw"]
    except KeyError:
        if prev_job_options is None:
            raise FioStatException("did not have job options while parsing: %s" % str(src))
        rw = prev_job_options["rw"]

    uuid_found = src["uuid"]
    bs_str = src["global_options"]["bs"]
    bs_KiB = int(bs_str.split("KiB")[0])
    numjobs = int(src["global_options"]["numjobs"])

    if rw == "randwrite" or rw == "write":
        result_data = src["fio"]["write"]
    elif rw == "randread" or rw == "read":
        result_data = src["fio"]["read"]
    elif rw == "randrw" or rw == "rw":
        raise FioStatException("this program does not handle read-write mix yet")
    else:
        raise FioStatException("unrecognized workload type: %s" % rw)

    bw = result_data["bw"]
    iops = result_data["iops"]
    elapsed = float(result_data["runtime"]) / MSEC_PER_SEC
    pod = src["fio"]["hostname"]

    # build up a tree optype -> sample -> pod -> thread
    # so we can compute stats

    # optype layer
    try:
        optype_blksizes = optype_dict[rw]
    except KeyError:
        optype_blksizes = {}
        optype_dict[rw] = optype_blksizes

    # block size layer
    try:
        blksize_samples = optype_blksizes[bs_KiB]
    except KeyError:
        blksize_samples = {}
        optype_blksizes[bs_KiB] = blksize_samples

    # sample layer
    if max_sample < sample:
        max_sample = sample
    try:
        sample_pods = blksize_samples[sample]
    except KeyError:
        sample_pods = {}
        blksize_samples[sample] = sample_pods

    # pod layer
    try:
        jobs_in_pod = sample_pods[pod]
    except KeyError:
        jobs_in_pod = []
        sample_pods[pod] = jobs_in_pod

    # job layer - no identifier for per-job info
    jobs_in_pod.append((iops, bw, elapsed))

# now validate data

print(
    "  op-type,      block-size,  sample,      pod,           process,        "
    + "iops, bw (KiB/s), elapsed-time (sec), %deviation"
)
try:
    for optype in sorted(optype_dict.keys()):
        optype_blksizes = optype_dict[optype]
        for bs in optype_blksizes.keys():
            blksize_samples = optype_blksizes[bs]
            sample_list_keys = sorted(blksize_samples.keys())
            if len(sample_list_keys) < max_sample:
                raise FioStatException(
                    "op-type %s blksize %s does not have %d samples, has only %d samples"
                    % (optype, bs, max_sample, len(sample_list_keys))
                )
            total_iops_samples = []
            max_elapsed_by_sample = []
            for s in sorted(sample_list_keys):
                sample_pods = blksize_samples[s]
                sample_pods_keys = sample_pods.keys()
                if pods_per_run == 0:
                    pods_per_run = len(sample_pods_keys)
                elif len(sample_pods_keys) < pods_per_run:
                    print(
                        "WARNING: only %d pods found in optype %s bs %s sample %d, expected %d"
                        % (len(sample_pods_keys), optype, bs, s, pods_per_run)
                    )
                total_MBps_in_sample = 0.0
                total_iops_in_sample = 0.0
                max_elapsed_sec = 0.0
                iops_in_sample = []
                for p in sorted(sample_pods_keys):
                    jobs_in_pod = sample_pods[p]
                    for k, job in enumerate(jobs_in_pod):
                        (iops, bw, elapsed) = job
                        total_MBps_in_sample += bw
                        total_iops_in_sample += iops
                        if elapsed > max_elapsed_sec:
                            max_elapsed_sec = elapsed
                        iops_in_sample.append(iops)
                        print(
                            "%10s, %5d, %14d, %14s, %16d, %9.1f, %8.3f, %8.1f"
                            % (optype, bs, s, p, k + 1, iops, bw, elapsed)
                        )
                # sample_pods['_MiB_per_sec'] = total_MiB_per_sec
                # sample_pods['_iops'] = total_iops
                # compute total IOPS and %deviation
                iops_array = numpy.array(iops_in_sample)
                mean_iops_in_sample = total_iops_in_sample / len(iops_in_sample)
                iops_pct_dev_in_sample = numpy.std(iops_array) * 100.0 / mean_iops_in_sample
                max_elapsed_by_sample.append(max_elapsed_sec)
                print(
                    "%10s, %5d, %14d,     add-pods,      add-processes, %9.1f, %8.3f, %8.1f, %8.3f"
                    % (
                        optype,
                        bs,
                        s,
                        total_iops_in_sample,
                        total_MBps_in_sample,
                        max_elapsed_sec,
                        iops_pct_dev_in_sample,
                    )
                )
                print("")

                total_iops_samples.append(total_iops_in_sample)
            total_iops_samples_array = numpy.array(total_iops_samples)
            mean_iops = numpy.average(total_iops_samples_array)
            mean_MBps = mean_iops * bs / KiB_per_MiB
            pct_dev_iops = 100.0 * numpy.std(total_iops_samples_array) / mean_iops
            max_elapsed_across_samples = numpy.max(numpy.array(max_elapsed_by_sample))
            print(
                "%10s, %5d, across-samples,     add-pods,      add-processes, %9.1f, %8.3f, %8.1f, %8.3f"
                % (optype, bs, mean_iops, mean_MBps, max_elapsed_across_samples, pct_dev_iops)
            )
            print("")
            print("")

except FioStatException as e:
    print(e)
    print("if data is incomplete, maybe test did not finish yet?")
    sys.exit(NOTOK)
