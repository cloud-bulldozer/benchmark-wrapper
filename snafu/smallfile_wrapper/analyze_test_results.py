#!/usr/bin/python3
# script to calculate statistics from raw elasticsearch results 
# generated by benchmark-wrapper/smallfile

import os, sys
from datetime import datetime
from snafu.utils.fetch_es_test_results import connect_es, next_result
import json
import numpy

KiB_per_MiB = 1 << 10

class SMFStatException(Exception):
    pass

index_name = 'ripsaw-smallfile-results'
# used by strptime()
datetime_format = '%Y-%m-%dT%H:%M:%S.%f%z'

if len(sys.argv) < 2:
    print('ERROR: must supply uuid of test')
    sys.exit(1)

uuid = sys.argv[1]
print('uuid is %s' % uuid)

uuid_query = {
  "query": {
    "simple_query_string": {
        "query": uuid,
        "fields": [ 'uuid' ],
        "default_operator": "and"
    }
  }
}

def getenv_with_default( nm, default ):
    e = os.getenv(nm)
    return e if e else default


es = connect_es()

optype_dict = {}
max_sample = 0
threads_per_pod = None
pods_per_run = 0

hit_generator = next_result(es, index_name, uuid)
for hit in hit_generator:
        src = hit['_source']
        uuid_found = src['uuid']

        #print(json.dumps(src, indent=2))
        sample = int(src['sample'])
        files = int(src['files'])
        records = int(src['records'])
        file_size_KiB = int(src['params']['file-size'])
        files_per_sec = float(src['files-per-sec'])
        MiB_per_sec = files_per_sec * file_size_KiB / KiB_per_MiB
        elapsed = float(src['elapsed'])
        iops = float(records) / elapsed
        optype = src['optype']
        thrd_id = int(src['tid'])
        # host is really pod name
        host = src['host']
        if not threads_per_pod:
            threads_per_pod = int(src['params']['threads'])

        # build up a tree optype -> sample -> pod -> thread
        # so we can compute stats

        # optype layer
        try:
            optype_samples = optype_dict[optype]
        except KeyError:
            optype_samples = {}
            optype_dict[optype] = optype_samples

        if max_sample < sample:
            max_sample = sample

        # sample layer
        try:
            sample_pods = optype_samples[sample]
        except KeyError:
            sample_pods = {}
            optype_samples[sample] = sample_pods

        # pod layer
        try:
            sample_threads = sample_pods[host]
        except KeyError:
            sample_threads = {}
            sample_pods[host] = sample_threads

        # thread layer (can be multiple threads per pod)
        try:
            any_prev_tupl = sample_threads[thrd_id]
            raise SMFStatException('2 samples with same optype and thread ID should not happen: %s' %
                                    str(src))
        except KeyError:
            # this is the NORMAL case
            tupl = (elapsed, files, files_per_sec, MiB_per_sec, iops)
            sample_threads[thrd_id] = tupl

# now validate data

print('optypes in test: %s' % str(optype_dict.keys()))
print('')

print('   optype, sample, pod,                            thread, files, files/sec, MiB/s, IOPS, elapsed, %dev')
for optype in sorted(optype_dict.keys()):
    optype_samples = optype_dict[optype]
    sample_list_keys = sorted(optype_samples.keys())
    if len(sample_list_keys) < max_sample:
        print('WARNING: op-type %s does not have %d samples, has only %d samples' % 
                                (optype, max_sample, len(sample_list_keys)))
    fps_samples = []
    for s in sorted(sample_list_keys):
        sample_pods = optype_samples[s]
        sample_pods_keys = sample_pods.keys()
        if pods_per_run == 0:
            pods_per_run = len(sample_pods_keys)
        elif len(sample_pods_keys) < pods_per_run:
            print('WARNING: only %d pods found in optype %s sample %d, expected %d' % 
                    (len(sample_pods_keys), optype, s, pods_per_run))
        total_files = 0
        total_files_per_sec = 0.0
        total_MiB_per_sec = 0.0
        total_iops = 0.0
        elapsed_times = []
        for p in sorted(sample_pods_keys):
            sample_threads = sample_pods[p]
            sample_threads_keys = sample_threads.keys()
            if len(sample_threads_keys) != threads_per_pod:
                print('WARNING: only %d threads found, expected %d' % 
                        (len(sample_threads_keys), threads_per_pod))
            for t in sorted(sample_threads_keys):
                (elapsed, files, files_per_sec, MB_per_sec, iops) = sample_threads[t]
                total_MiB_per_sec += MiB_per_sec
                total_files_per_sec += files_per_sec
                total_iops += iops
                total_files += files
                print('%10s, %2d, %-40s, %3s, %d, %f, %f, %f' % 
                        (optype, s, p, t, files, files_per_sec, MB_per_sec, elapsed))
                elapsed_times.append(elapsed)
        sample_pods['_MiB_per_sec'] = total_MiB_per_sec
        sample_pods['_files_per_sec'] = total_files_per_sec
        sample_pods['_iops'] = total_iops
        sample_pods['_elapsed_mean'] = mean_elapsed = sum(elapsed_times)/len(elapsed_times)
        sample_pods['_elapsed_pctdev'] = pctdev = numpy.std(numpy.array(elapsed_times)) * 100.0 / mean_elapsed
        print('%10s, %2d, %-40s, %3s, %d, %f, %f, %f, %f, %f' % (optype, s, 'all-pods', 'all-threads', total_files, total_files_per_sec, total_MiB_per_sec, total_iops, mean_elapsed, pctdev))
        fps_samples.append(total_files_per_sec)
    fps_mean_across_samples = numpy.average(fps_samples)
    fps_pctdev_across_samples = 100.0 * numpy.std(fps_samples) / fps_mean_across_samples
    print('%10s, mean fps %f, %% dev fps %f' % 
            (optype, fps_mean_across_samples, fps_pctdev_across_samples))
    if len(fps_samples) < 3:
        print('WARNING: only %d samples for op %s, percent deviation cannot be measured' %
                (len(fps_samples), optype))
